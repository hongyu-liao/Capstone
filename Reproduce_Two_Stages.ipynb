{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stage 1: Convert PDF to JSON using Docling VLM pipeline via LM Studio\n",
        "from Functions.utils_logging import setup_basic_logging\n",
        "setup_basic_logging()\n",
        "\n",
        "from Functions.pdf_to_json import convert_pdf_with_lmstudio\n",
        "\n",
        "# Configure input PDF and output directory\n",
        "PDF_SOURCE = r\"Sample Papers/1-s2.0-S1385110124000054-main.pdf\"  # Change to your PDF path if needed\n",
        "OUTPUT_DIR = \"output_lmstudio_conversion\"\n",
        "\n",
        "# Run conversion\n",
        "json_path = convert_pdf_with_lmstudio(\n",
        "    PDF_SOURCE,\n",
        "    OUTPUT_DIR,\n",
        "    lm_studio_url=\"http://localhost:1234/v1/chat/completions\",\n",
        "    model_identifier=\"google/gemma-3-12b-it-gguf\",\n",
        "    prompt=\"Parse the document.\",\n",
        "    max_tokens=16384,\n",
        "    generate_page_images=True,\n",
        ")\n",
        "print(\"JSON saved to:\", json_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-11 19:13:37,845 - INFO - Functions.pipeline_steps - Processing picture 1/8...\n",
            "2025-08-11 19:13:38,222 - INFO - Functions.pipeline_steps - Marking non-informative image #1 for removal\n",
            "2025-08-11 19:13:38,223 - INFO - Functions.pipeline_steps - Processing picture 2/8...\n",
            "2025-08-11 19:13:38,427 - INFO - Functions.pipeline_steps - Marking non-informative image #2 for removal\n",
            "2025-08-11 19:13:38,427 - INFO - Functions.pipeline_steps - Processing picture 3/8...\n",
            "2025-08-11 19:13:38,650 - INFO - Functions.pipeline_steps - Marking non-informative image #3 for removal\n",
            "2025-08-11 19:13:38,650 - INFO - Functions.pipeline_steps - Processing picture 4/8...\n",
            "c:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\Functions\\image_analysis.py:118: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  ddgs = DDGS()\n",
            "2025-08-11 19:13:42,831 - INFO - primp - response: https://www.bing.com/search?q=Arabic+NLP+Text+Summarization 200\n",
            "2025-08-11 19:13:46,949 - INFO - Functions.pipeline_steps - Processing picture 5/8...\n",
            "c:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\Functions\\image_analysis.py:118: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  ddgs = DDGS()\n",
            "2025-08-11 19:13:50,388 - INFO - primp - response: https://www.bing.com/search?q=machine+translation+natural+language+processing 200\n",
            "2025-08-11 19:13:53,629 - INFO - Functions.pipeline_steps - Processing picture 6/8...\n",
            "2025-08-11 19:13:59,566 - INFO - Functions.pipeline_steps - Attempting chart data extraction for picture #6...\n",
            "2025-08-11 19:13:59,567 - INFO - Functions.chart_extraction - Extracting chart data from picture #6 using DePlot...\n",
            "2025-08-11 19:14:25,548 - WARNING - Functions.chart_extraction - Failed to parse DePlot output for picture #6\n",
            "2025-08-11 19:14:26,582 - INFO - Functions.pipeline_steps - Processing picture 7/8...\n",
            "2025-08-11 19:14:32,174 - INFO - Functions.pipeline_steps - Attempting chart data extraction for picture #7...\n",
            "2025-08-11 19:14:32,174 - INFO - Functions.chart_extraction - Extracting chart data from picture #7 using DePlot...\n",
            "2025-08-11 19:15:02,942 - WARNING - Functions.chart_extraction - Failed to parse DePlot output for picture #7\n",
            "2025-08-11 19:15:03,977 - INFO - Functions.pipeline_steps - Processing picture 8/8...\n",
            "2025-08-11 19:15:10,323 - INFO - Functions.pipeline_steps - Attempting chart data extraction for picture #8...\n",
            "2025-08-11 19:15:10,324 - INFO - Functions.chart_extraction - Extracting chart data from picture #8 using DePlot...\n",
            "2025-08-11 19:17:12,132 - WARNING - Functions.chart_extraction - Failed to parse DePlot output for picture #8\n",
            "2025-08-11 19:17:13,219 - INFO - Functions.pipeline_steps - Enhanced Step 1 complete. Enhanced JSON saved to: C:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\PDF_Analyzer_App\\output\\applsci-14-07088-v2_with_descriptions_and_chart_data.json\n",
            "2025-08-11 19:17:13,293 - INFO - Functions.pipeline_steps - Step 2 complete. NLP-ready JSON saved to: C:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\PDF_Analyzer_App\\output\\applsci-14-07088-v2_nlp_ready.json (images removed: 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1 success: True\n",
            "Enhanced JSON: C:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\PDF_Analyzer_App\\output\\applsci-14-07088-v2_with_descriptions_and_chart_data.json\n",
            "Step 2 success: True\n",
            "NLP-ready JSON: C:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\PDF_Analyzer_App\\output\\applsci-14-07088-v2_nlp_ready.json\n",
            "Verification OK: True\n",
            "{'total_pictures': 5, 'no_images_ok': True, 'with_ai_analysis': 5, 'with_nonempty_description': 5, 'with_web_context': 2, 'with_chart_data': 0, 'images_keys_found': 0}\n"
          ]
        }
      ],
      "source": [
        "# Stage 2: Process Docling JSON -> Enhanced JSON -> NLP-ready JSON (with inline verification)\n",
        "# This cell re-imports libraries and re-reads files to keep the two stages fully separated.\n",
        "from Functions.utils_logging import setup_basic_logging\n",
        "setup_basic_logging()\n",
        "\n",
        "from Functions.pipeline_steps import (\n",
        "    step1_add_ai_descriptions_with_chart_extraction,\n",
        "    step2_remove_all_images,\n",
        ")\n",
        "from Functions.verification import verify_final_json\n",
        "\n",
        "# Set the source JSON produced in Stage 1 (update this path to match your Stage 1 output)\n",
        "DOC_JSON_SOURCE = r\"C:\\\\Users\\\\Hongyu\\\\OneDrive - Northwestern University\\\\NU\\\\Capstone\\\\PDF_Analyzer_App\\\\output\\\\applsci-14-07088-v2.json\"\n",
        "\n",
        "# Step 1: Add AI descriptions + optional chart data extraction and web search\n",
        "success1, enhanced_path = step1_add_ai_descriptions_with_chart_extraction(\n",
        "    DOC_JSON_SOURCE,\n",
        "    lm_studio_url=\"http://localhost:1234/v1/chat/completions\",\n",
        "    model_name=\"google/gemma-3-12b-it-gguf\",\n",
        "    enable_chart_extraction=True,\n",
        "    enable_web_search_for_conceptual=True,\n",
        "    sleep_between_images_s=1.0,\n",
        ")\n",
        "print(\"Step 1 success:\", success1)\n",
        "print(\"Enhanced JSON:\", enhanced_path)\n",
        "\n",
        "# Step 2: Remove all images -> NLP-ready JSON and verify inline\n",
        "if success1 and enhanced_path:\n",
        "    success2, nlp_ready_path = step2_remove_all_images(enhanced_path)\n",
        "    print(\"Step 2 success:\", success2)\n",
        "    print(\"NLP-ready JSON:\", nlp_ready_path)\n",
        "\n",
        "    if success2 and nlp_ready_path:\n",
        "        summary = verify_final_json(nlp_ready_path, require_no_images=True, min_description_length=20)\n",
        "        print(\"Verification OK:\", summary.get(\"ok\"))\n",
        "        print({k: summary[k] for k in [\n",
        "            \"total_pictures\",\"no_images_ok\",\"with_ai_analysis\",\"with_nonempty_description\",\n",
        "            \"with_web_context\",\"with_chart_data\",\"images_keys_found\"\n",
        "        ]})\n",
        "        if summary.get(\"per_picture_issues\"):\n",
        "            print(\"Per-picture issues:\")\n",
        "            for issue in summary[\"per_picture_issues\"]:\n",
        "                print(issue)\n",
        "else:\n",
        "    print(\"Stage 2 aborted: Stage 1 failed or no enhanced JSON path.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch260",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
