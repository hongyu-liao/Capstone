{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc5b75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 01:19:03,033 - INFO - üìÑ Loading document from: 1-s2.0-S1385110124000054-main-google_gemma-3-12b-it-gguf.json\n",
      "2025-07-29 01:19:03,092 - INFO - ‚úÖ Document loaded successfully.\n",
      "2025-07-29 01:19:03,092 - INFO - üíæ Saving to HTML with embedded images...\n",
      "2025-07-29 01:19:03,162 - WARNING - Could not parse formula with MathML\n",
      "2025-07-29 01:19:03,201 - INFO - üéâ Success! HTML file generated at: C:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\output_lmstudio_conversion\\1-s2.0-S1385110124000054-main-google_gemma-3-12b-it-gguf.html\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# -------------------[ Docling Imports ]-------------------\n",
    "# We only need the DoclingDocument class to load the data,\n",
    "# and ImageRefMode to specify the output format.\n",
    "try:\n",
    "    from docling_core.types.doc.document import DoclingDocument\n",
    "    # ImageRefMode should be imported from docling_core.types.doc.base\n",
    "    from docling_core.types.doc.base import ImageRefMode\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Could not import core Docling classes: {e}\")\n",
    "    print(\"Please ensure 'docling' and its dependencies are correctly installed.\")\n",
    "    print(\"Try running: pip install --upgrade docling docling-core\")\n",
    "    exit()\n",
    "\n",
    "# -------------------[ Configuration ]-------------------\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# -------------------[ Main Conversion Function ]-------------------\n",
    "def convert_json_to_html(json_path_str: str):\n",
    "    \"\"\"\n",
    "    Loads a DoclingDocument from a JSON file and exports it as a\n",
    "    self-contained HTML file with embedded images.\n",
    "\n",
    "    Args:\n",
    "        json_path_str (str): The path to the input .json file.\n",
    "    \"\"\"\n",
    "    json_path = Path(json_path_str)\n",
    "    if not json_path.is_file():\n",
    "        logging.error(f\"‚ùå JSON file not found: {json_path}\")\n",
    "        return\n",
    "\n",
    "    # --- Step 1: Load the DoclingDocument from the JSON file ---\n",
    "    logging.info(f\"üìÑ Loading document from: {json_path.name}\")\n",
    "    try:\n",
    "        # Read the JSON file as text\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_str = f.read()\n",
    "        # Use model_validate_json to load the document from JSON string (Pydantic v2+)\n",
    "        document = DoclingDocument.model_validate_json(json_str)\n",
    "        logging.info(\"‚úÖ Document loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"A critical error occurred while loading the JSON file: {e}\", exc_info=True)\n",
    "        return\n",
    "\n",
    "    # --- Step 2: Save the Document as a Self-Contained HTML File ---\n",
    "    # Define the output path for the new HTML file\n",
    "    output_html_path = json_path.with_suffix(\".html\")\n",
    "    \n",
    "    logging.info(f\"üíæ Saving to HTML with embedded images...\")\n",
    "    try:\n",
    "        # Use ImageRefMode.EMBEDDED to create a single, portable HTML file\n",
    "        document.save_as_html(\n",
    "            output_html_path,\n",
    "            image_mode=ImageRefMode.EMBEDDED\n",
    "        )\n",
    "        logging.info(f\"üéâ Success! HTML file generated at: {output_html_path.resolve()}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save document as HTML: {e}\", exc_info=True)\n",
    "        return\n",
    "\n",
    "# -------------------[ Script Execution ]-------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # This should be the JSON file generated by the previous script.\n",
    "    # It will likely be in the 'output_smoldocling' folder.\n",
    "    JSON_FILE_TO_PROCESS = r\"C:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\output_lmstudio_conversion\\1-s2.0-S1385110124000054-main-google_gemma-3-12b-it-gguf.json\"\n",
    "    \n",
    "    convert_json_to_html(JSON_FILE_TO_PROCESS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ed9fbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 23:03:24,612 - INFO - üìÑ Loading document from: 1-s2.0-S1385110124000054-main-google_gemma-3-12b-it-gguf_nlp_ready.json\n",
      "2025-07-21 23:03:24,623 - INFO - ‚ö†Ô∏è Original format failed, trying to clean JSON for compatibility...\n",
      "2025-07-21 23:03:24,626 - INFO -    üóëÔ∏è Removed nlp_ready_metadata for compatibility\n",
      "2025-07-21 23:03:24,646 - ERROR - ‚ùå Failed to load document after cleaning JSON. The file may have broken references or unsupported structure.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# -------------------[ Docling Imports ]-------------------\n",
    "try:\n",
    "    from docling_core.types.doc.document import DoclingDocument\n",
    "    from docling_core.types.doc.base import ImageRefMode\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Could not import core Docling classes: {e}\")\n",
    "    print(\"Please ensure 'docling' and its dependencies are correctly installed.\")\n",
    "    print(\"Try running: pip install --upgrade docling docling-core\")\n",
    "    exit()\n",
    "\n",
    "# -------------------[ Configuration ]-------------------\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def is_valid_docling_json(json_str):\n",
    "    \"\"\"\n",
    "    Try to validate the JSON string as a DoclingDocument.\n",
    "    Returns the document if valid, otherwise None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        document = DoclingDocument.model_validate_json(json_str)\n",
    "        return document\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def clean_json_for_docling(json_str: str):\n",
    "    \"\"\"\n",
    "    Clean the JSON to make it compatible with DoclingDocument format.\n",
    "    Removes AI-added fields and attempts to fix broken references that might cause validation errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Remove metadata that might cause issues\n",
    "        metadata_keys_to_remove = [\n",
    "            'step1_metadata', \n",
    "            'nlp_ready_metadata', \n",
    "            'enhancement_metadata'\n",
    "        ]\n",
    "        for key in metadata_keys_to_remove:\n",
    "            if key in data:\n",
    "                del data[key]\n",
    "                logging.info(f\"   üóëÔ∏è Removed {key} for compatibility\")\n",
    "\n",
    "        # Clean pictures array - remove AI analysis fields but keep structure\n",
    "        if 'pictures' in data and isinstance(data['pictures'], list):\n",
    "            cleaned_pictures = []\n",
    "            for pic in data['pictures']:\n",
    "                cleaned_pic = {}\n",
    "\n",
    "                # Keep essential fields, remove AI analysis\n",
    "                essential_fields = ['self_ref', 'captions', 'prov', 'bbox']\n",
    "                for field in essential_fields:\n",
    "                    if field in pic:\n",
    "                        cleaned_pic[field] = pic[field]\n",
    "\n",
    "                # Keep image data if it exists (for original files)\n",
    "                if 'image' in pic:\n",
    "                    cleaned_pic['image'] = pic['image']\n",
    "\n",
    "                # For NLP-ready files, we might want to add a text representation\n",
    "                # where the image used to be\n",
    "                if 'ai_analysis' in pic and 'image' not in pic:\n",
    "                    # Create a text placeholder for where the image was\n",
    "                    description = pic['ai_analysis'].get('description') or pic['ai_analysis'].get('detailed_description', 'Image description not available')\n",
    "                    # Add as a caption or text element\n",
    "                    if 'captions' not in cleaned_pic:\n",
    "                        cleaned_pic['captions'] = []\n",
    "                    cleaned_pic['captions'].append({\n",
    "                        'text': f\"[AI Description: {description}]\",\n",
    "                        'type': 'ai_generated'\n",
    "                    })\n",
    "\n",
    "                cleaned_pictures.append(cleaned_pic)\n",
    "\n",
    "            data['pictures'] = cleaned_pictures\n",
    "            logging.info(f\"   üßπ Cleaned {len(cleaned_pictures)} pictures for compatibility\")\n",
    "\n",
    "        # Attempt to fix broken references in 'body' and 'furniture' if present\n",
    "        # This is a workaround for \"list index out of range\" errors in DoclingDocument validation\n",
    "        for section in ['body', 'furniture']:\n",
    "            if section in data and isinstance(data[section], list):\n",
    "                # Remove any references that are out of bounds\n",
    "                # This is a naive fix: remove any child_ref with invalid index\n",
    "                def filter_valid_refs(nodes, parent_path=\"\"):\n",
    "                    valid_nodes = []\n",
    "                    for idx, node in enumerate(nodes):\n",
    "                        # If node has 'children', recursively filter them\n",
    "                        if isinstance(node, dict) and 'children' in node and isinstance(node['children'], list):\n",
    "                            node['children'] = filter_valid_refs(node['children'], parent_path + f\"/{section}[{idx}]\")\n",
    "                        # If node has a 'ref' or similar, check if it is valid (skip for now)\n",
    "                        valid_nodes.append(node)\n",
    "                    return valid_nodes\n",
    "                data[section] = filter_valid_refs(data[section])\n",
    "\n",
    "        return json.dumps(data, indent=2, ensure_ascii=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to clean JSON: {e}\")\n",
    "        return json_str  # Return original if cleaning fails\n",
    "\n",
    "# -------------------[ Main Conversion Function ]-------------------\n",
    "def convert_json_to_html(json_path_str: str):\n",
    "    \"\"\"\n",
    "    Loads a DoclingDocument from a JSON file and exports it as a\n",
    "    self-contained HTML file. Handles both original and AI-enhanced JSON files.\n",
    "    Tries to clean the JSON and fix broken references if validation fails.\n",
    "    \"\"\"\n",
    "    json_path = Path(json_path_str)\n",
    "    if not json_path.is_file():\n",
    "        logging.error(f\"‚ùå JSON file not found: {json_path}\")\n",
    "        return\n",
    "\n",
    "    # --- Step 1: Load and clean the JSON if necessary ---\n",
    "    logging.info(f\"üìÑ Loading document from: {json_path.name}\")\n",
    "    try:\n",
    "        # Read the JSON file as text\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_str = f.read()\n",
    "\n",
    "        # Try loading directly first\n",
    "        document = is_valid_docling_json(json_str)\n",
    "        if document:\n",
    "            logging.info(\"‚úÖ Document loaded successfully (original format).\")\n",
    "        else:\n",
    "            logging.info(\"‚ö†Ô∏è Original format failed, trying to clean JSON for compatibility...\")\n",
    "            # Clean the JSON to make it compatible with DoclingDocument\n",
    "            cleaned_json_str = clean_json_for_docling(json_str)\n",
    "            document = is_valid_docling_json(cleaned_json_str)\n",
    "            if document:\n",
    "                logging.info(\"‚úÖ Document loaded successfully (cleaned format).\")\n",
    "            else:\n",
    "                logging.error(\"‚ùå Failed to load document after cleaning JSON. The file may have broken references or unsupported structure.\")\n",
    "                return\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"A critical error occurred while loading the JSON file: {e}\", exc_info=True)\n",
    "        return\n",
    "\n",
    "    # --- Step 2: Save the Document as a Self-Contained HTML File ---\n",
    "    # Define the output path for the new HTML file\n",
    "    output_html_path = json_path.with_suffix(\".html\")\n",
    "\n",
    "    logging.info(f\"üíæ Saving to HTML...\")\n",
    "    try:\n",
    "        # Use ImageRefMode.EMBEDDED to create a single, portable HTML file\n",
    "        # For NLP-ready files without images, this will show the text content\n",
    "        document.save_as_html(\n",
    "            output_html_path,\n",
    "            image_mode=ImageRefMode.EMBEDDED\n",
    "        )\n",
    "        logging.info(f\"üéâ Success! HTML file generated at: {output_html_path.resolve()}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save document as HTML: {e}\", exc_info=True)\n",
    "        return\n",
    "\n",
    "# -------------------[ Alternative Simple HTML Generator ]-------------------\n",
    "def convert_json_to_simple_html(json_path_str: str):\n",
    "    \"\"\"\n",
    "    Fallback method: Generate simple HTML directly from JSON content.\n",
    "    Use this if Docling method fails completely.\n",
    "    \"\"\"\n",
    "    json_path = Path(json_path_str)\n",
    "    if not json_path.is_file():\n",
    "        logging.error(f\"‚ùå JSON file not found: {json_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract main text\n",
    "        main_text = data.get('main_text', '')\n",
    "\n",
    "        # Simple HTML template\n",
    "        html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Document Content</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: 'Times New Roman', serif;\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 40px;\n",
    "            line-height: 1.6;\n",
    "            background-color: white;\n",
    "        }}\n",
    "        .content {{\n",
    "            white-space: pre-wrap;\n",
    "            text-align: justify;\n",
    "        }}\n",
    "        .ai-description {{\n",
    "            background-color: #f0f8ff;\n",
    "            border-left: 4px solid #007bff;\n",
    "            padding: 15px;\n",
    "            margin: 20px 0;\n",
    "            font-style: italic;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"content\">{main_text}</div>\n",
    "    \n",
    "    {generate_ai_descriptions(data.get('pictures', []))}\n",
    "    \n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "        # Save HTML\n",
    "        output_html_path = json_path.with_suffix(\"_simple.html\")\n",
    "        with open(output_html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html_content)\n",
    "\n",
    "        logging.info(f\"‚úÖ Simple HTML generated: {output_html_path.resolve()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate simple HTML: {e}\")\n",
    "\n",
    "def generate_ai_descriptions(pictures):\n",
    "    \"\"\"Generate HTML for AI descriptions of images.\"\"\"\n",
    "    if not pictures:\n",
    "        return \"\"\n",
    "\n",
    "    descriptions_html = \"\"\n",
    "    for i, pic in enumerate(pictures, 1):\n",
    "        if 'ai_analysis' in pic:\n",
    "            description = pic['ai_analysis'].get('description') or pic['ai_analysis'].get('detailed_description', 'No description available')\n",
    "            descriptions_html += f\"\"\"\n",
    "            <div class=\"ai-description\">\n",
    "                <strong>Figure {i} Description:</strong><br>\n",
    "                {description}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "    return descriptions_html\n",
    "\n",
    "# -------------------[ Script Execution ]-------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the JSON file to process\n",
    "    JSON_FILE_TO_PROCESS = r\"C:\\Users\\Hongyu\\OneDrive - Northwestern University\\NU\\Capstone\\output_lmstudio_conversion\\1-s2.0-S1385110124000054-main-google_gemma-3-12b-it-gguf_nlp_ready.json\"\n",
    "\n",
    "    # Try the main Docling method\n",
    "    try:\n",
    "        convert_json_to_html(JSON_FILE_TO_PROCESS)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Main conversion failed: {e}\")\n",
    "        logging.info(\"Trying fallback method...\")\n",
    "        convert_json_to_simple_html(JSON_FILE_TO_PROCESS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch260",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
